{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "17219f18",
      "metadata": {
        "id": "17219f18"
      },
      "source": [
        "## **Classification_Naive_Bayes**\n",
        "\n",
        "Este es un problema de clasificación de texto y análisis de sentimiento utilizando el algoritmo de Naive Bayes. El objetivo es clasificar las revisiones de productos de Amazon en positivas o negativas basado en el contenido textual de las reseñas.\n",
        "\n",
        "Se ingresa reviews positivos y negativos de un producto de Amazon y se construye la bolsa de palabras que corresponden a revisiones negativas y positivas. A partir de allí, se entrena un modelo Naive-Bayes, para predecir si una nueva revisión es positiva o negativa.\n",
        "\n",
        "**Nota:** La primer parte del código realiza una clasificación del comentario que se le ingrese. La segunda parte realiza lo mismo solo que se puede escoger que cantidad de comentarios que se ingresara para no tener que ejecutar el código cada vez que se quiera ingresar un nuevo comentario."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Predecir si **una** revisión es positiva o negativa"
      ],
      "metadata": {
        "id": "ohn8GLDezh9L"
      },
      "id": "ohn8GLDezh9L"
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO\n",
        "import nltk\n",
        "from google.colab import files\n",
        "\n",
        "nltk.download('punkt')\n",
        "\n",
        "def main():\n",
        "    # Read data from files uploaded to Colab\n",
        "    positives = load_text(\"Navaja_positivo.txt\")\n",
        "    negatives = load_text(\"Navaja_negativo.txt\")\n",
        "\n",
        "    # Create a set of all words\n",
        "    words = set()\n",
        "    words.update(positives)\n",
        "    words.update(negatives)\n",
        "\n",
        "    # Extract features from text\n",
        "    training = []\n",
        "    training.extend(generate_features(positives, words, \"Positive\"))\n",
        "    training.extend(generate_features(negatives, words, \"Negative\"))\n",
        "\n",
        "    # Classify a new sample\n",
        "    classifier = nltk.NaiveBayesClassifier.train(training)\n",
        "\n",
        "    # Input a text for classification\n",
        "    s = input(\"Ingrese un texto para clasificar: \")\n",
        "    result = classify(classifier, s, words)\n",
        "\n",
        "    # Print the probabilities\n",
        "    for key in result.samples():\n",
        "        print(f\"{key}: {result.prob(key):.4f}\")\n",
        "\n",
        "def load_text(file_name):\n",
        "    with open(file_name, 'r', encoding='utf-8') as file:\n",
        "        text = file.read().lower()\n",
        "        return extract_words(text)\n",
        "\n",
        "def extract_words(document):\n",
        "    return set(\n",
        "        word.lower() for word in nltk.word_tokenize(document)\n",
        "        if any(c.isalpha() for c in word)\n",
        "    )\n",
        "\n",
        "def generate_features(documents, words, label):\n",
        "    features = []\n",
        "    for document in documents:\n",
        "        features.append(({\n",
        "            word: (word in document)\n",
        "            for word in words\n",
        "        }, label))\n",
        "    return features\n",
        "\n",
        "def classify(classifier, document, words):\n",
        "    document_words = extract_words(document)\n",
        "    features = {\n",
        "        word: (word in document_words)\n",
        "        for word in words\n",
        "    }\n",
        "    return classifier.prob_classify(features)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b6WpF6uJfBBH",
        "outputId": "3a844bd8-f7ac-4c50-cfa0-53c6e8bf9802"
      },
      "id": "b6WpF6uJfBBH",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ingrese un texto para clasificar: Es excelente\n",
            "Positive: 0.7933\n",
            "Negative: 0.2067\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Predecir si **n** revisiones es positiva o negativa"
      ],
      "metadata": {
        "id": "afjtoTuQzw4S"
      },
      "id": "afjtoTuQzw4S"
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from google.colab import files\n",
        "\n",
        "nltk.download('punkt')\n",
        "\n",
        "def train_classifier(positives, negatives, words):\n",
        "    # Extract features from text\n",
        "    training = []\n",
        "    training.extend(generate_features(positives, words, \"Positive\"))\n",
        "    training.extend(generate_features(negatives, words, \"Negative\"))\n",
        "\n",
        "    # Train the classifier\n",
        "    classifier = nltk.NaiveBayesClassifier.train(training)\n",
        "    return classifier\n",
        "\n",
        "def main():\n",
        "    # Read data from files uploaded to Colab\n",
        "    positives = load_text(\"Navaja_positivo.txt\")\n",
        "    negatives = load_text(\"Navaja_negativo.txt\")\n",
        "\n",
        "    # Create a set of all words\n",
        "    words = set()\n",
        "    words.update(positives)\n",
        "    words.update(negatives)\n",
        "\n",
        "    # Train the classifier\n",
        "    classifier = train_classifier(positives, negatives, words)\n",
        "\n",
        "    # Classify multiple samples\n",
        "    num_samples = int(input(\"Ingrese el número de textos para clasificar: \"))\n",
        "    for _ in range(num_samples):\n",
        "        s = input(\"Ingrese un texto para clasificar: \")\n",
        "        result = classify(classifier, s, words)\n",
        "\n",
        "        # Print the probabilities\n",
        "        for key in result.samples():\n",
        "            print(f\"{key}: {result.prob(key):.4f}\")\n",
        "\n",
        "def load_text(file_name):\n",
        "    with open(file_name, 'r', encoding='utf-8') as file:\n",
        "        text = file.read().lower()\n",
        "        return extract_words(text)\n",
        "\n",
        "def extract_words(document):\n",
        "    return set(\n",
        "        word.lower() for word in nltk.word_tokenize(document)\n",
        "        if any(c.isalpha() for c in word)\n",
        "    )\n",
        "\n",
        "def generate_features(documents, words, label):\n",
        "    features = []\n",
        "    for document in documents:\n",
        "        features.append(({\n",
        "            word: (word in document)\n",
        "            for word in words\n",
        "        }, label))\n",
        "    return features\n",
        "\n",
        "def classify(classifier, document, words):\n",
        "    document_words = extract_words(document)\n",
        "    features = {\n",
        "        word: (word in document_words)\n",
        "        for word in words\n",
        "    }\n",
        "    return classifier.prob_classify(features)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AmzY2Hfpu6uU",
        "outputId": "b9782ea0-7b72-44f4-f212-f1e6983644cf"
      },
      "id": "AmzY2Hfpu6uU",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ingrese el número de textos para clasificar: 3\n",
            "Ingrese un texto para clasificar: Me defraudo mucho\n",
            "Positive: 0.0508\n",
            "Negative: 0.9492\n",
            "Ingrese un texto para clasificar: Es muy buena\n",
            "Positive: 0.7907\n",
            "Negative: 0.2093\n",
            "Ingrese un texto para clasificar: Falta funciones, muy sencilla\n",
            "Positive: 0.2115\n",
            "Negative: 0.7885\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "ohn8GLDezh9L",
        "afjtoTuQzw4S"
      ]
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}